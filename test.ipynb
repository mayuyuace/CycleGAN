{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=1, cuda=False, dataroot='my_datasets/', generator_A2B='results/netG_A2Bgpu.pth', generator_B2A='results/netG_B2Agpu.pth', input_nc=3, n_cpu=8, output_nc=3, size=256)\n",
      "10\n",
      "Generated images 0010 of 0010\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features)  ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block       \n",
    "        model = [   nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(input_nc, 64, 7),\n",
    "                    nn.InstanceNorm2d(64),\n",
    "                    nn.ReLU(inplace=True) ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        # Output layer\n",
    "        model += [  nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(64, output_nc, 7),\n",
    "                    nn.Tanh() ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, '%s/A' % mode) + '/*.*'))\n",
    "        self.files_A = self.files_A[0:2000]\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, '%s/B' % mode) + '/*.*'))\n",
    "        self.files_B = self.files_B[0:2000]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n",
    "\n",
    "        if self.unaligned:\n",
    "            item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]))\n",
    "        else:\n",
    "            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\n",
    "\n",
    "        return {'A': item_A, 'B': item_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batchSize', type=int, default=1, help='size of the batches')\n",
    "parser.add_argument('--dataroot', type=str, default='my_datasets/', help='root directory of the dataset')\n",
    "parser.add_argument('--input_nc', type=int, default=3, help='number of channels of input data')\n",
    "parser.add_argument('--output_nc', type=int, default=3, help='number of channels of output data')\n",
    "parser.add_argument('--size', type=int, default=256, help='size of the data (squared assumed)')\n",
    "parser.add_argument('--cuda', action='store_true', help='use GPU computation')\n",
    "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
    "parser.add_argument('--generator_A2B', type=str, default='results/netG_A2Bgpu.pth', help='A2B generator checkpoint file')\n",
    "parser.add_argument('--generator_B2A', type=str, default='results/netG_B2Agpu.pth', help='B2A generator checkpoint file')\n",
    "opt = parser.parse_known_args()[0]\n",
    "print(opt)\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "###### Definition of variables ######\n",
    "# Networks\n",
    "netG_A2B = Generator(opt.input_nc, opt.output_nc)\n",
    "netG_B2A = Generator(opt.output_nc, opt.input_nc)\n",
    "\n",
    "if opt.cuda:\n",
    "    netG_A2B.cuda()\n",
    "    netG_B2A.cuda()\n",
    "\n",
    "# Load state dicts\n",
    "netG_A2B.load_state_dict(torch.load(opt.generator_A2B, map_location=lambda storage, loc: storage))\n",
    "netG_B2A.load_state_dict(torch.load(opt.generator_B2A, map_location=lambda storage, loc: storage))\n",
    "\n",
    "# Set model's test mode\n",
    "netG_A2B.eval()\n",
    "netG_B2A.eval()\n",
    "\n",
    "# Inputs & targets memory allocation\n",
    "Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor\n",
    "input_A = Tensor(opt.batchSize, opt.input_nc, opt.size, opt.size)\n",
    "input_B = Tensor(opt.batchSize, opt.output_nc, opt.size, opt.size)\n",
    "\n",
    "# Dataset loader\n",
    "# transforms_ = [ transforms.ToTensor(),\n",
    "#                 transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "transforms_ = [ transforms.Resize(int(opt.size*1.12), Image.BICUBIC), \n",
    "                transforms.RandomCrop(opt.size), \n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset(opt.dataroot, transforms_=transforms_, mode='test'), \n",
    "                        batch_size=opt.batchSize, shuffle=False, num_workers=opt.n_cpu)\n",
    "###################################\n",
    "print(len(dataloader))\n",
    "###### Testing######\n",
    "\n",
    "# Create output dirs if they don't exist\n",
    "if not os.path.exists('results/A'):\n",
    "    os.makedirs('results/A')\n",
    "if not os.path.exists('results/B'):\n",
    "    os.makedirs('results/B')\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    # Set model input\n",
    "    real_A = Variable(input_A.copy_(batch['A']))\n",
    "    real_B = Variable(input_B.copy_(batch['B']))\n",
    "\n",
    "    # Generate output\n",
    "    fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\n",
    "    fake_A = 0.5*(netG_B2A(real_B).data + 1.0)\n",
    "\n",
    "    # Save image files\n",
    "    save_image(fake_A, 'results/A/%04d.jpg' % (i+1))\n",
    "    save_image(fake_B, 'results/B/%04d.jpg' % (i+1))\n",
    "    \n",
    "    sys.stdout.write('\\rGenerated images %04d of %04d' % (i+1, len(dataloader)))\n",
    "\n",
    "sys.stdout.write('\\n')\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
